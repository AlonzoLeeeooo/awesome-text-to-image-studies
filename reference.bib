% ----------------TEXT-TO-IMAGE GENERATION---------------------
@inproceedings{ding-etal-2021-cogview,
  author       = {{Ming Ding and
                  Zhuoyi Yang and
                  Wenyi Hong and
                  Wendi Zheng and
                  Chang Zhou and
                  Da Yin and
                  Junyang Lin and
                  Xu Zou and
                  Zhou Shao and
                  Hongxia Yang and
                  Jie Tang}},
  title        = {{CogView: Mastering Text-to-Image Generation via Transformers}},
  booktitle    = {NeurIPS},
  pages        = {19822--19835},
  year         = {2021},
}

@inproceedings{ramesh-etal-2021-dalle1,
  author       = {{Aditya Ramesh and
                  Mikhail Pavlov and
                  Gabriel Goh and
                  Scott Gray and
                  Chelsea Voss and
                  Alec Radford and
                  Mark Chen and
                  Ilya Sutskever}},
  title        = {{Zero-Shot Text-to-Image Generation}},
  booktitle    = {ICML},
  series       = {Proceedings of Machine Learning Research},
  volume       = {139},
  pages        = {8821--8831},
  year         = {2021},
}

@inproceedings{rombach-etal-2022-stable-diffusion,
  author       = {{Robin Rombach and
                  Andreas Blattmann and
                  Dominik Lorenz and
                  Patrick Esser and
                  Bj{\"{o}}rn Ommer}},
  title        = {{High-Resolution Image Synthesis with Latent Diffusion Models}},
  booktitle    = {CVPR},
  pages        = {10674--10685},
  year         = {2022},
}

@inproceedings{gu-etal-2022-vector,
  author       = {{Shuyang Gu and
                  Dong Chen and
                  Jianmin Bao and
                  Fang Wen and
                  Bo Zhang and
                  Dongdong Chen and
                  Lu Yuan and
                  Baining Guo}},
  title        = {{Vector Quantized Diffusion Model for Text-to-Image Synthesis}},
  booktitle    = {CVPR},
  pages        = {10686--10696},
  year         = {2022},
}

@inproceedings{tao-etal-2022-dfgan,
  author       = {{Ming Tao and
                  Hao Tang and
                  Fei Wu and
                  Xiaoyuan Jing and
                  Bing{-}Kun Bao and
                  Changsheng Xu}},
  title        = {{{DF-GAN:} {A} Simple and Effective Baseline for Text-to-Image Synthesis}},
  booktitle    = {CVPR},
  pages        = {16494--16504},
  year         = {2022},
}

@inproceedings{zhou-etal-2022-lafite,
  author       = {{Yufan Zhou and
                  Ruiyi Zhang and
                  Changyou Chen and
                  Chunyuan Li and
                  Chris Tensmeyer and
                  Tong Yu and
                  Jiuxiang Gu and
                  Jinhui Xu and
                  Tong Sun}},
  title        = {{Towards Language-Free Training for Text-to-Image Generation}},
  booktitle    = {CVPR},
  pages        = {17886--17896},
  year         = {2022},
}

@inproceedings{wu-etal-2022-text,
  author       = {{Fuxiang Wu and
                  Liu Liu and
                  Fusheng Hao and
                  Fengxiang He and
                  Jun Cheng}},
  title        = {{Text-to-Image Synthesis based on Object-Guided Joint-Decoding Transformer}},
  booktitle    = {CVPR},
  pages        = {18092--18101},
  year         = {2022},
}

@inproceedings{li-etal-2022-stylet2i,
  author       = {{Zhiheng Li and
                  Martin Renqiang Min and
                  Kai Li and
                  Chenliang Xu}},
  title        = {{StyleT2I: Toward Compositional and High-Fidelity Text-to-Image Synthesis}},
  booktitle    = {CVPR},
  pages        = {18176--18186},
  year         = {2022},
}

@inproceedings{kim-etal-2022-diffusionclip,
  author       = {{Gwanghyun Kim and
                  Taesung Kwon and
                  Jong Chul Ye}},
  title        = {{DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation}},
  booktitle    = {CVPR},
  pages        = {2416--2425},
  year         = {2022},
}

@inproceedings{ding-etal-2022-cogview2,
  author       = {{Ming Ding and
                  Wendi Zheng and
                  Wenyi Hong and
                  Jie Tang}},
  title        = {{CogView2: Faster and Better Text-to-Image Generation via Hierarchical
                  Transformers}},
  booktitle    = {NeurIPS},
  year         = {2022},
}

@inproceedings{saharia-etal-2022-imagen,
  author       = {{Chitwan Saharia and
                  William Chan and
                  Saurabh Saxena and
                  Lala Li and
                  Jay Whang and
                  Emily L. Denton and
                  Seyed Kamyar Seyed Ghasemipour and
                  Raphael Gontijo Lopes and
                  Burcu Karagol Ayan and
                  Tim Salimans and
                  Jonathan Ho and
                  David J. Fleet and
                  Mohammad Norouzi}},
  title        = {{Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding}},
  booktitle    = {NeurIPS},
  year         = {2022},
}

@article{ramesh-etal-2022-dalle2,
  author       = {{Aditya Ramesh and
                  Prafulla Dhariwal and
                  Alex Nichol and
                  Casey Chu and
                  Mark Chen}},
  title        = {{Hierarchical Text-Conditional Image Generation with {CLIP} Latents}},
  journal      = {CoRR},
  volume       = {abs/2204.06125},
  year         = {2022},
}

@inproceedings{
xu2023imagereward,
title={{ImageReward: Learning and Evaluating Human Preferences for Text-to-Image Generation}},
author={{Jiazheng Xu and Xiao Liu and Yuchen Wu and Yuxuan Tong and Qinkai Li and Ming Ding and Jie Tang and Yuxiao Dong}},
booktitle={NeurIPS},
year={2023},
}

@inproceedings{betker-etal-2023-dalle3,
  title={{Improving Image Generation with Better Captions}},
  author={{James Betker and Gabriel Goh and Li Jing and † TimBrooks and Jianfeng Wang and Linjie Li and † LongOuyang and † JuntangZhuang and † JoyceLee and † YufeiGuo and † WesamManassra and † PrafullaDhariwal and † CaseyChu and † YunxinJiao and Aditya Ramesh}},
}

@article{voynov-etal-2023-promptplus,
  author       = {{Andrey Voynov and
                  Qinghao Chu and
                  Daniel Cohen{-}Or and
                  Kfir Aberman}},
  title        = {{{P+:} Extended Textual Conditioning in Text-to-Image Generation}},
  journal      = {CoRR},
  volume       = {abs/2303.09522},
  year         = {2023},
}

@article{podell-etal-2023-sdxl,
  author       = {{Dustin Podell and
                  Zion English and
                  Kyle Lacey and
                  Andreas Blattmann and
                  Tim Dockhorn and
                  Jonas M{\"{u}}ller and
                  Joe Penna and
                  Robin Rombach}},
  title        = {{{SDXL:} Improving Latent Diffusion Models for High-Resolution Image
                  Synthesis}},
  journal      = {CoRR},
  volume       = {abs/2307.01952},
  year         = {2023},
}

@article{sauer-etal-2023-sdxl-turbo,
  author       = {{Axel Sauer and
                  Dominik Lorenz and
                  Andreas Blattmann and
                  Robin Rombach}},
  title        = {{Adversarial Diffusion Distillation}},
  journal      = {CoRR},
  volume       = {abs/2311.17042},
  year         = {2023},
}

@inproceedings{sauer-etal-2023-stylegant,
  author       = {{Axel Sauer and
                  Tero Karras and
                  Samuli Laine and
                  Andreas Geiger and
                  Timo Aila}},
  title        = {{StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image
                  Synthesis}},
  booktitle    = {ICML},
  volume       = {202},
  pages        = {30105--30118},
  year         = {2023},
}

@inproceedings{kang-etal-2023-gigagan,
  author       = {{Minguk Kang and
                  Jun{-}Yan Zhu and
                  Richard Zhang and
                  Jaesik Park and
                  Eli Shechtman and
                  Sylvain Paris and
                  Taesung Park}},
  title        = {{Scaling up GANs for Text-to-Image Synthesis}},
  booktitle    = {CVPR},
  pages        = {10124--10134},
  year         = {2023},
}

@misc{pernias-etal-2023-wuerstchen,
      title={{Wuerstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models}}, 
      author={{Pablo Pernias and Dominic Rampas and Mats L. Richter and Christopher J. Pal and Marc Aubreville}},
      year={2023},
      eprint={2306.00637},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{feng-etal-2023-ernie-vilg,
  author       = {{Zhida Feng and
                  Zhenyu Zhang and
                  Xintong Yu and
                  Yewei Fang and
                  Lanxin Li and
                  Xuyi Chen and
                  Yuxiang Lu and
                  Jiaxiang Liu and
                  Weichong Yin and
                  Shikun Feng and
                  Yu Sun and
                  Li Chen and
                  Hao Tian and
                  Hua Wu and
                  Haifeng Wang}},
  title        = {{ERNIE-ViLG 2.0: Improving Text-to-Image Diffusion Model with Knowledge-Enhanced
                  Mixture-of-Denoising-Experts}},
  booktitle    = {CVPR},
  pages        = {10135--10145},
  year         = {2023},
}

@inproceedings{zhong-etal-2023-sur-adapter,
  author       = {{Shanshan Zhong and
                  Zhongzhan Huang and
                  Wushao Wen and
                  Jinghui Qin and
                  Liang Lin}},
  title        = {{SUR-adapter: Enhancing Text-to-Image Pre-trained Diffusion Models
                  with Large Language Models}},
  booktitle    = {ACM MM},
  pages        = {567--578},
  year         = {2023},
}

@article{chefer-etal-2023-attend-and-excite,
  author       = {{Hila Chefer and
                  Yuval Alaluf and
                  Yael Vinker and
                  Lior Wolf and
                  Daniel Cohen{-}Or}},
  title        = {{Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image
                  Diffusion Models}},
  journal      = {SIGGRAPH},
  pages        = {148:1--148:10},
  year         = {2023},
}

@inproceedings{chang-etal-2023-muse,
  author       = {{Huiwen Chang and
                  Han Zhang and
                  Jarred Barber and
                  Aaron Maschinot and
                  Jos{\'{e}} Lezama and
                  Lu Jiang and
                  Ming{-}Hsuan Yang and
                  Kevin Patrick Murphy and
                  William T. Freeman and
                  Michael Rubinstein and
                  Yuanzhen Li and
                  Dilip Krishnan}},
  title        = {{Muse: Text-To-Image Generation via Masked Generative Transformers}},
  booktitle    = {ICML},
  pages        = {4055--4075},
  year         = {2023},
}

% ----------------CONDITIONAL TEXT-TO-IMAGE GENERATION---------------------

@article{wang-etal-2023-piti,
  author       = {{Tengfei Wang and
                  Ting Zhang and
                  Bo Zhang and
                  Hao Ouyang and
                  Dong Chen and
                  Qifeng Chen and
                  Fang Wen}},
  title        = {{Pretraining is All You Need for Image-to-Image Translation}},
  year         = {2022},
}

@inproceedings{li-etal-2023-gligen,
  author       = {{Yuheng Li and
                  Haotian Liu and
                  Qingyang Wu and
                  Fangzhou Mu and
                  Jianwei Yang and
                  Jianfeng Gao and
                  Chunyuan Li and
                  Yong Jae Lee}},
  title        = {{{GLIGEN:} Open-Set Grounded Text-to-Image Generation}},
  booktitle    = {CVPR},
  pages        = {22511--22521},
  year         = {2023},
}

@inproceedings{zhang-etal-2023-controlnet,
  author       = {{Lvmin Zhang and
                  Anyi Rao and
                  Maneesh Agrawala}},
  title        = {{Adding Conditional Control to Text-to-Image Diffusion Models}},
  booktitle    = {ICCV},
  pages        = {3813--3824},
  year         = {2023},
}

@article{mou-etal-2023-t2i-adapter,
  author       = {{Chong Mou and
                  Xintao Wang and
                  Liangbin Xie and
                  Jian Zhang and
                  Zhongang Qi and
                  Ying Shan and
                  Xiaohu Qie}},
  title        = {{T2I-Adapter: Learning Adapters to Dig out More Controllable Ability
                  for Text-to-Image Diffusion Models}},
  journal      = {CoRR},
  year         = {2023},
}

@inproceedings{huang-etal-2023-composer,
  author       = {{Lianghua Huang and
                  Di Chen and
                  Yu Liu and
                  Yujun Shen and
                  Deli Zhao and
                  Jingren Zhou}},
  title        = {{Composer: Creative and Controllable Image Synthesis with Composable
                  Conditions}},
  booktitle    = {ICML},
  pages        = {13753--13773},
  year         = {2023},
}

@inproceedings{voynov-etal-2023-sketch,
  author       = {{Andrey Voynov and
                  Kfir Aberman and
                  Daniel Cohen{-}Or}},
  title        = {{Sketch-Guided Text-to-Image Diffusion Models}},
  booktitle    = {SIGGRAPH},
  pages        = {55:1--55:11},
  year         = {2023},
}

@inproceedings{bartal-etal-2023-multidiffusion,
  author       = {{Omer Bar{-}Tal and
                  Lior Yariv and
                  Yaron Lipman and
                  Tali Dekel}},
  title        = {{MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation}},
  booktitle    = {ICML},
  pages        = {1737--1752},
  year         = {2023},}
}

@inproceedings{avrahami-etal-2023-spatext,
  author       = {{Omri Avrahami and
                  Thomas Hayes and
                  Oran Gafni and
                  Sonal Gupta and
                  Yaniv Taigman and
                  Devi Parikh and
                  Dani Lischinski and
                  Ohad Fried and
                  Xi Yin}},
  title        = {{SpaText: Spatio-Textual Representation for Controllable Image Generation}},
  booktitle    = {CVPR},
  pages        = {18370--18380},
  year         = {2023},
}

@misc{zhao-etal-2023-unicontrolnet,
      title={{Uni-ControlNet: All-in-One Control to Text-to-Image Diffusion Models}}, 
      author={{Shihao Zhao and Dongdong Chen and Yen-Chun Chen and Jianmin Bao and Shaozhe Hao and Lu Yuan and Kwan-Yee K. Wong}},
      year={2023},
      eprint={2305.16322},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{
wang-etal-2023-incontext,
title={{In-Context Learning Unlocked for Diffusion Models}},
author={{Zhendong Wang and Yifan Jiang and Yadong Lu and yelong shen and Pengcheng He and Weizhu Chen and Zhangyang Wang and Mingyuan Zhou}},
booktitle={NeurIPS},
year={2023},
}

@inproceedings{liu-etal-2023-more,
  author       = {{Xihui Liu and
                  Dong Huk Park and
                  Samaneh Azadi and
                  Gong Zhang and
                  Arman Chopikyan and
                  Yuxiao Hu and
                  Humphrey Shi and
                  Anna Rohrbach and
                  Trevor Darrell}},
  title        = {{More Control for Free! Image Synthesis with Semantic Diffusion Guidance}},
  booktitle    = {WACV},
  pages        = {289--299},
  year         = {2023},
}

@article{chen-etal-2024-training,
  author       = {{Minghao Chen and
                  Iro Laina and
                  Andrea Vedaldi}},
  title        = {{Training-Free Layout Control with Cross-Attention Guidance}},
  journal      = {CoRR},
  volume       = {abs/2304.03373},
  year         = {2024},
}

% ----------------PERSONALIZED TEXT-TO-IMAGE GENERATION---------------------
@inproceedings{kumari-etal-2023-custom-diffusion,
  author       = {{Nupur Kumari and
                  Bingliang Zhang and
                  Richard Zhang and
                  Eli Shechtman and
                  Jun{-}Yan Zhu}},
  title        = {{Multi-Concept Customization of Text-to-Image Diffusion}},
  booktitle    = {CVPR},
  pages        = {1931--1941},
  year         = {2023},
}

@inproceedings{ruiz-etal-2023-dreambooth,
  author       = {{Nataniel Ruiz and
                  Yuanzhen Li and
                  Varun Jampani and
                  Yael Pritch and
                  Michael Rubinstein and
                  Kfir Aberman}},
  title        = {{DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven
                  Generation}},
  booktitle    = {CVPR},
  pages        = {22500--22510},
  year         = {2023},
}

@inproceedings{wei-etal-2023-elite,
  author       = {{Yuxiang Wei and
                  Yabo Zhang and
                  Zhilong Ji and
                  Jinfeng Bai and
                  Lei Zhang and
                  Wangmeng Zuo}},
  title        = {{{ELITE:} Encoding Visual Concepts into Textual Embeddings for Customized
                  Text-to-Image Generation}},
  booktitle    = {ICCV},
  pages        = {15897--15907},
  year         = {2023},
}

@inproceedings{gal-etal-2023-textual-inversion,
  author       = {{Rinon Gal and
                  Yuval Alaluf and
                  Yuval Atzmon and
                  Or Patashnik and
                  Amit Haim Bermano and
                  Gal Chechik and
                  Daniel Cohen{-}Or}},
  title        = {{An Image is Worth One Word: Personalizing Text-to-Image Generation
                  using Textual Inversion}},
  booktitle    = {ICLR},
  year         = {2023},
}

@inproceedings{avrahami-etal-2023-break-a-scene,
  author       = {{Omri Avrahami and
                  Kfir Aberman and
                  Ohad Fried and
                  Daniel Cohen{-}Or and
                  Dani Lischinski}},
  title        = {{Break-A-Scene: Extracting Multiple Concepts from a Single Image}},
  booktitle    = {SIGGRAPH},
  pages        = {96:1--96:12},
  year         = {2023},
}

@article{shi-etal-2023-instantbooth,
  author       = {{Jing Shi and
                  Wei Xiong and
                  Zhe Lin and
                  Hyun Joon Jung}},
  title        = {{InstantBooth: Personalized Text-to-Image Generation without Test-Time
                  Finetuning}},
  journal      = {CoRR},
  volume       = {abs/2304.03411},
  year         = {2023},
}

@article{gal-etal-2023-encoder,
  author       = {{Rinon Gal and
                  Moab Arar and
                  Yuval Atzmon and
                  Amit H. Bermano and
                  Gal Chechik and
                  Daniel Cohen{-}Or}},
  title        = {{Encoder-based Domain Tuning for Fast Personalization of Text-to-Image
                  Models}},
  journal      = {{ACM} Trans. Graph.},
  volume       = {42},
  number       = {4},
  pages        = {150:1--150:13},
  year         = {2023},
}


% ----------------TEXT-GUIDED IMAGE MANIPULATION---------------------

@inproceedings{cao-etal-2023-masactrl,
  author       = {{Mingdeng Cao and
                  Xintao Wang and
                  Zhongang Qi and
                  Ying Shan and
                  Xiaohu Qie and
                  Yinqiang Zheng}},
  title        = {{MasaCtrl: Tuning-Free Mutual Self-Attention Control for Consistent
                  Image Synthesis and Editing}},
  booktitle    = {ICCV},
  pages        = {22503--22513},
  year         = {2023},
}

@inproceedings{patashnik-etal-2023-localizing,
  author       = {{Or Patashnik and
                  Daniel Garibi and
                  Idan Azuri and
                  Hadar Averbuch{-}Elor and
                  Daniel Cohen{-}Or}},
  title        = {{Localizing Object-level Shape Variations with Text-to-Image Diffusion
                  Models}},
  booktitle    = {ICCV},
  pages        = {22994--23004},
  year         = {2023},
}